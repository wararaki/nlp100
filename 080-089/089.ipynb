{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e215878dfcfd0ef8bbb92b360f853e8f0796a48f9e143eedb671ef2205a4259f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from module import Word2VecIdConverter, sentence2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10672, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.txt', sep='\\t')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = Word2VecIdConverter('data/mapping.csv', 'data/GoogleNews-vectors-negative300.bin')\n",
    "n_words = converter.get_n_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "weights = w2v.wv.syn0\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10672"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "results = map(sentence2words, train_df.title)\n",
    "results = map(converter.word2id, results)\n",
    "X = list(map(lambda x: torch.Tensor(x).long(), results))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor(train_df.category.map({'b': 0, 't': 1, 'e': 2, 'm': 3}).to_list()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 kernel_size: int,\n",
    "                 weights: np.ndarray):\n",
    "        super(CNN, self).__init__()\n",
    "        self._hidden_size = hidden_size\n",
    "        self._kernel_size = kernel_size\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, input_size)\n",
    "        self.embedding.weight = torch.nn.Parameter(torch.from_numpy(weights))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=hidden_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            bias=True\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(hidden_size*5*99, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.max_pool2d(x, kernel_size=(self._kernel_size, self._kernel_size))\n",
    "        x = x.view(-1, self._hidden_size*5*99)\n",
    "        x = self.linear(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = 300\n",
    "dh = 50\n",
    "n_class = 4\n",
    "kernel_size = 3\n",
    "cnn = CNN(vocab_size=n_words, input_size=dw, hidden_size=dh, output_size=n_class, kernel_size=kernel_size, weights=weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1- loss: 86.28493183851242, accuracy: 0.5902083333333333\n",
      "epoch 2- loss: 47.82752722501755, accuracy: 0.7822916666666667\n",
      "epoch 3- loss: 36.54272583127022, accuracy: 0.8284375\n",
      "epoch 4- loss: 31.49660536646843, accuracy: 0.8507291666666666\n",
      "epoch 5- loss: 28.259257674217224, accuracy: 0.8661458333333333\n",
      "epoch 6- loss: 25.99043382704258, accuracy: 0.87625\n",
      "epoch 7- loss: 24.14384587109089, accuracy: 0.8865625\n",
      "epoch 8- loss: 22.235573932528496, accuracy: 0.8972916666666667\n",
      "epoch 9- loss: 20.305023714900017, accuracy: 0.9083333333333333\n",
      "epoch 10- loss: 18.557565093040466, accuracy: 0.9178125\n",
      "epoch 11- loss: 16.99018655717373, accuracy: 0.9280208333333333\n",
      "epoch 12- loss: 15.558308206498623, accuracy: 0.9369791666666667\n",
      "epoch 13- loss: 14.233071625232697, accuracy: 0.9427083333333334\n",
      "epoch 14- loss: 13.001017540693283, accuracy: 0.9492708333333333\n",
      "epoch 15- loss: 11.856257431209087, accuracy: 0.9561458333333334\n",
      "epoch 16- loss: 10.798105597496033, accuracy: 0.961875\n",
      "epoch 17- loss: 9.830118209123611, accuracy: 0.968125\n",
      "epoch 18- loss: 8.956264726817608, accuracy: 0.9723958333333333\n",
      "epoch 19- loss: 8.18213814496994, accuracy: 0.9753125\n",
      "epoch 20- loss: 7.519527468830347, accuracy: 0.9788541666666667\n",
      "epoch 21- loss: 6.98820786178112, accuracy: 0.9817708333333334\n",
      "epoch 22- loss: 6.622342057526112, accuracy: 0.9825\n",
      "epoch 23- loss: 6.511237151920795, accuracy: 0.9814583333333333\n",
      "epoch 24- loss: 6.835780367255211, accuracy: 0.9760416666666667\n",
      "epoch 25- loss: 7.701386213302612, accuracy: 0.9690625\n",
      "epoch 26- loss: 8.880460985004902, accuracy: 0.956875\n",
      "epoch 27- loss: 8.782401064410806, accuracy: 0.9580208333333333\n",
      "epoch 28- loss: 10.158082524314523, accuracy: 0.9504166666666667\n",
      "epoch 29- loss: 10.313328925520182, accuracy: 0.9483333333333334\n",
      "epoch 30- loss: 9.373649628832936, accuracy: 0.9539583333333334\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "n_train_size = 9600\n",
    "X_train = X[:n_train_size]\n",
    "y_train = y[:n_train_size]\n",
    "X_pad = torch.nn.utils.rnn.pad_sequence(X_train, batch_first=True)\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = cnn(X_pad[i:i+batch_size].cuda())\n",
    "        loss = criterion(y_pred, y_train[i:i+batch_size].cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (y_pred.argmax(1) == y_train[i:i+batch_size].cuda()).sum().item()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'epoch {epoch}- loss: {running_loss}, accuracy: {correct/y_train.shape[0]}')\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([3, 2, 0, 3, 2, 0, 2, 2, 0, 2], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y_pred.argmax(dim=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}