{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('.pyenv': pyenv)",
   "metadata": {
    "interpreter": {
     "hash": "e215878dfcfd0ef8bbb92b360f853e8f0796a48f9e143eedb671ef2205a4259f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from module import Word2IdConverter, sentence2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10672, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.txt', sep='\\t')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = Word2IdConverter('data/mapping.csv')\n",
    "n_words = converter.get_n_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10672"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "results = map(sentence2words, train_df.title)\n",
    "results = map(converter.word2id, results)\n",
    "X = list(map(lambda x: torch.Tensor(x).long(), results))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor(train_df.category.map({'b': 0, 't': 1, 'e': 2, 'm': 3}).to_list()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int, input_size: int, hidden_size: int, output_size: int):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, input_size)\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x, hidden)\n",
    "        x = self.linear(x[:, -1])\n",
    "        return torch.log_softmax(x, dim=1)\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = 300\n",
    "dh = 50\n",
    "n_class = 4\n",
    "rnn = RNN(vocab_size=n_words, input_size=dw, hidden_size=dh, output_size=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_size = 10000\n",
    "X_train = X[:n_train_size]\n",
    "y_train = y[:n_train_size]\n",
    "#X_train = X\n",
    "#y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1: 1.3007311820983887\n",
      "epoch 2: 1.366949439048767\n",
      "epoch 3: 1.341908574104309\n",
      "epoch 4: 1.258305311203003\n",
      "epoch 5: 1.219605565071106\n",
      "epoch 6: 1.3363806009292603\n",
      "epoch 7: 1.3595890998840332\n",
      "epoch 8: 1.2084068059921265\n",
      "epoch 9: 1.2250587940216064\n",
      "epoch 10: 1.3382012844085693\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 256\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    optimizer.step()\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_pad = torch.nn.utils.rnn.pad_sequence(X_train[i:i+batch_size], batch_first=True)\n",
    "        h_0 = torch.zeros(1*X_pad.shape[1]*dh).reshape(1, X_pad.shape[1], dh)\n",
    "\n",
    "        y_pred = rnn(X_pad, h_0)\n",
    "        loss = criterion(y_pred, y_train[i:i+batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch {epoch}: {loss.item()}')\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "y_pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}