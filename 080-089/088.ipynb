{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e215878dfcfd0ef8bbb92b360f853e8f0796a48f9e143eedb671ef2205a4259f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from module import Word2IdConverter, sentence2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10672, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.txt', sep='\\t')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = Word2IdConverter('data/mapping.csv')\n",
    "n_words = converter.get_n_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10672"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "results = map(sentence2words, train_df.title)\n",
    "results = map(converter.word2id, results)\n",
    "X = list(map(lambda x: torch.Tensor(x).long(), results))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor(train_df.category.map({'b': 0, 't': 1, 'e': 2, 'm': 3}).to_list()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 kernel_size: int):\n",
    "        super(CNN, self).__init__()\n",
    "        self._hidden_size = hidden_size\n",
    "        self._kernel_size = kernel_size\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, input_size)\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=hidden_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            bias=True\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(hidden_size*5*99, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.max_pool2d(x, kernel_size=(self._kernel_size, self._kernel_size))\n",
    "        x = x.view(-1, self._hidden_size*5*99)\n",
    "        x = self.linear(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = 300\n",
    "dh = 50\n",
    "n_class = 4\n",
    "kernel_size = 3\n",
    "cnn = CNN(vocab_size=n_words, input_size=dw, hidden_size=dh, output_size=n_class, kernel_size=kernel_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1- loss: 173.71395802497864, accuracy: 0.4721875\n",
      "epoch 2- loss: 80.6879352927208, accuracy: 0.6117708333333334\n",
      "epoch 3- loss: 62.52748650312424, accuracy: 0.7184375\n",
      "epoch 4- loss: 47.35523107647896, accuracy: 0.7810416666666666\n",
      "epoch 5- loss: 33.319269359111786, accuracy: 0.8380208333333333\n",
      "epoch 6- loss: 24.347454965114594, accuracy: 0.890625\n",
      "epoch 7- loss: 20.82871699333191, accuracy: 0.9016666666666666\n",
      "epoch 8- loss: 16.88555385172367, accuracy: 0.9207291666666667\n",
      "epoch 9- loss: 13.701288122683764, accuracy: 0.9388541666666667\n",
      "epoch 10- loss: 8.890491854399443, accuracy: 0.9636458333333333\n",
      "epoch 11- loss: 6.465276751667261, accuracy: 0.97375\n",
      "epoch 12- loss: 4.327330857515335, accuracy: 0.98625\n",
      "epoch 13- loss: 3.6924655716866255, accuracy: 0.9895833333333334\n",
      "epoch 14- loss: 3.0161969298496842, accuracy: 0.9928125\n",
      "epoch 15- loss: 2.5247365729883313, accuracy: 0.9951041666666667\n",
      "epoch 16- loss: 2.6038650376722217, accuracy: 0.9942708333333333\n",
      "epoch 17- loss: 2.82177910534665, accuracy: 0.9929166666666667\n",
      "epoch 18- loss: 2.7994009798858315, accuracy: 0.9904166666666666\n",
      "epoch 19- loss: 2.88420729781501, accuracy: 0.9904166666666666\n",
      "epoch 20- loss: 2.5843219626694918, accuracy: 0.9903125\n",
      "epoch 21- loss: 0.5978176270145923, accuracy: 0.9986458333333333\n",
      "epoch 22- loss: 0.5429060596507043, accuracy: 0.99875\n",
      "epoch 23- loss: 0.47945031139533967, accuracy: 0.99875\n",
      "epoch 24- loss: 0.4394952056463808, accuracy: 0.9988541666666667\n",
      "epoch 25- loss: 0.4387922612950206, accuracy: 0.99875\n",
      "epoch 26- loss: 0.4395516157383099, accuracy: 0.99875\n",
      "epoch 27- loss: 0.43967794196214527, accuracy: 0.99875\n",
      "epoch 28- loss: 0.43630315680638887, accuracy: 0.99875\n",
      "epoch 29- loss: 0.4278841220366303, accuracy: 0.9988541666666667\n",
      "epoch 30- loss: 0.4056968686345499, accuracy: 0.9989583333333333\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "n_train_size = 9600\n",
    "X_train = X[:n_train_size]\n",
    "y_train = y[:n_train_size]\n",
    "X_pad = torch.nn.utils.rnn.pad_sequence(X_train, batch_first=True)\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = cnn(X_pad[i:i+batch_size].cuda())\n",
    "        loss = criterion(y_pred, y_train[i:i+batch_size].cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (y_pred.argmax(1) == y_train[i:i+batch_size].cuda()).sum().item()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'epoch {epoch}- loss: {running_loss}, accuracy: {correct/y_train.shape[0]}')\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.argmax(dim=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}