{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e215878dfcfd0ef8bbb92b360f853e8f0796a48f9e143eedb671ef2205a4259f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from module import Word2IdConverter, sentence2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10672, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.txt', sep='\\t')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = Word2IdConverter('data/mapping.csv')\n",
    "n_words = converter.get_n_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10672"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "results = map(sentence2words, train_df.title)\n",
    "results = map(converter.word2id, results)\n",
    "X = list(map(lambda x: torch.Tensor(x).long(), results))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor(train_df.category.map({'b': 0, 't': 1, 'e': 2, 'm': 3}).to_list()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int,\n",
    "                 output_size: int,\n",
    "                 kernel_size: int):\n",
    "        super(CNN, self).__init__()\n",
    "        self._hidden_size = hidden_size\n",
    "        self._kernel_size = kernel_size\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, input_size)\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=hidden_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            bias=True\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(hidden_size*5*99, output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = torch.max_pool2d(x, kernel_size=(self._kernel_size, self._kernel_size))\n",
    "        x = x.view(-1, self._hidden_size*5*99)\n",
    "        x = self.linear(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = 300\n",
    "dh = 50\n",
    "n_class = 4\n",
    "kernel_size = 3\n",
    "cnn = CNN(vocab_size=n_words, input_size=dw, hidden_size=dh, output_size=n_class, kernel_size=kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1- loss: 1.4820444583892822, accuracy: 0.145\n",
      "epoch 2- loss: 20.87087059020996, accuracy: 0.435\n",
      "epoch 3- loss: 70.64411926269531, accuracy: 0.392\n",
      "epoch 4- loss: 14.961731910705566, accuracy: 0.435\n",
      "epoch 5- loss: 45.07423782348633, accuracy: 0.392\n",
      "epoch 6- loss: 31.241729736328125, accuracy: 0.07\n",
      "epoch 7- loss: 26.482818603515625, accuracy: 0.435\n",
      "epoch 8- loss: 33.544498443603516, accuracy: 0.392\n",
      "epoch 9- loss: 28.559917449951172, accuracy: 0.103\n",
      "epoch 10- loss: 34.77330780029297, accuracy: 0.435\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "n_train_size = 1000\n",
    "X_train = X[:n_train_size]\n",
    "y_train = y[:n_train_size]\n",
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    optimizer.zero_grad()\n",
    "    X_pad = torch.nn.utils.rnn.pad_sequence(X_train, batch_first=True)\n",
    "    y_pred = cnn(X_pad)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = (y_pred.argmax(1) == y_train).sum().item() / y_train.shape[0]\n",
    "    print(f'epoch {epoch}- loss: {loss.item()}, accuracy: {accuracy}')\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "y_pred.argmax(dim=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}